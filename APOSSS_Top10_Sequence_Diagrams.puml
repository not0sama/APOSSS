@startuml APOSSS_Top10_Sequence_Diagrams

!define LIGHTBLUE #E3F2FD
!define LIGHTGREEN #E8F5E8
!define LIGHTYELLOW #FFF8E1
!define LIGHTPINK #FCE4EC
!define LIGHTGRAY #F5F5F5

title APOSSS System - Top 10 Most Important Sequence Diagrams

/' ================================================================================================
   DIAGRAM 1: Complete Search Process (Main Flow) - Core System Functionality
   ================================================================================================ '/

@startuml CompleteSearchProcess
!theme plain
title 1. Complete Search Process - Main AI-Powered Search Flow

actor User as U
participant "Frontend\n(JavaScript)" as FE
participant "Flask API\n(app.py)" as API
participant "QueryProcessor" as QP
participant "LLMProcessor" as LLM
participant "Gemini API" as GEMINI
participant "SearchEngine" as SE
participant "RankingEngine" as RE
participant "DatabaseManager" as DB
participant "FAISS Index" as FAISS
database "6 MongoDB\nDatabases" as MONGO

U -> FE: Submit search query
activate FE

FE -> API: POST /api/search\n{query, ranking_mode, filters}
activate API

API -> QP: process_query(user_query)
activate QP

QP -> LLM: process_query(user_query)
activate LLM

LLM -> GEMINI: analyze_query()\n- Language detection\n- Intent analysis\n- Entity extraction
activate GEMINI
GEMINI --> LLM: structured_analysis
deactivate GEMINI

LLM --> QP: processed_query\n{intent, entities, keywords, etc.}
deactivate LLM

QP --> API: validated_query_data
deactivate QP

API -> SE: search_all_databases(processed_query)
activate SE

par Parallel Search Operations
    SE -> FAISS: semantic_search(query_embedding)
    activate FAISS
    FAISS --> SE: semantic_results
    deactivate FAISS
else
    SE -> DB: query_all_databases()
    activate DB
    
    par Database Queries
        DB -> MONGO: Academic Library search
        DB -> MONGO: Experts System search  
        DB -> MONGO: Research Papers search
        DB -> MONGO: Laboratories search
        DB -> MONGO: Funding search
        DB -> MONGO: APOSSS search
    end
    
    DB --> SE: traditional_results
    deactivate DB
end

SE --> API: merged_search_results
deactivate SE

API -> RE: rank_search_results(results, processed_query)
activate RE

RE -> RE: Calculate multi-algorithm scores:\n- Heuristic scoring\n- TF-IDF similarity\n- Intent alignment\n- Embedding similarity\n- LTR prediction\n- Knowledge graph ranking

RE --> API: ranked_results\n{categorized, personalized}
deactivate RE

API --> FE: JSON Response\n{results, metadata, categories}
deactivate API

FE -> FE: Render search results\nwith relevance categories
FE --> U: Display ranked results
deactivate FE

note over U, MONGO
    Complete AI-powered search workflow:
    1. Natural language query processing
    2. Multi-database semantic + traditional search
    3. Advanced ML-based ranking
    4. Personalized result delivery
end note

@enduml

/' ================================================================================================
   DIAGRAM 2: Query Processing with LLM - AI Language Understanding
   ================================================================================================ '/

@startuml QueryProcessingLLM
!theme plain
title 2. Query Processing with LLM - AI Language Understanding

participant "QueryProcessor" as QP
participant "LLMProcessor" as LLM
participant "Gemini API" as GEMINI

-> QP: process_query("machine learning in medical diagnosis")
activate QP

QP -> QP: clean_and_validate(query)

QP -> LLM: process_query(cleaned_query)
activate LLM

LLM -> LLM: create_analysis_prompt(query)

LLM -> GEMINI: POST /v1/models/gemini-2.0-flash-exp:generateContent
activate GEMINI

note over GEMINI
    Comprehensive Analysis Request:
    - Language detection & translation
    - Spelling correction
    - Intent classification
    - Named entity recognition
    - Keyword extraction
    - Semantic expansion
    - Academic field mapping
end note

GEMINI -> GEMINI: Process with AI model:\n- Transformer analysis\n- Multi-language support\n- Context understanding

GEMINI --> LLM: JSON Response:\n{\n  "language_analysis": {...},\n  "query_processing": {...},\n  "intent_analysis": {...},\n  "entity_extraction": {...},\n  "keyword_analysis": {...},\n  "semantic_expansion": {...},\n  "academic_classification": {...}\n}
deactivate GEMINI

LLM -> LLM: validate_and_enhance_response()

LLM -> LLM: add_backward_compatibility()

LLM --> QP: Enhanced Query Data:\n{\n  "corrected_query": "...",\n  "intent": {"primary_intent": "find_research"},\n  "entities": {"technologies": [...], "concepts": [...]},\n  "keywords": {"primary": [...], "secondary": [...]},\n  "academic_fields": {"primary_field": "medical_ai"},\n  "confidence_scores": {...}\n}
deactivate LLM

QP -> QP: final_validation_and_stats()

QP --> : Structured Query Parameters
deactivate QP

note over QP, GEMINI
    Advanced NLP Pipeline:
    - Multi-language support (50+ languages)
    - Intent classification (8 types)
    - Entity extraction (10+ categories)
    - Semantic expansion with synonyms
    - Academic field mapping
    - Confidence scoring
end note

@enduml

/' ================================================================================================
   DIAGRAM 3: Multi-Algorithm Ranking Process - Intelligent Result Ranking
   ================================================================================================ '/

@startuml MultiAlgorithmRanking
!theme plain
title 3. Multi-Algorithm Ranking Process - Intelligent Result Ranking

participant "RankingEngine" as RE
participant "LTRRanker\n(XGBoost)" as LTR
participant "EmbeddingRanker\n(Transformers)" as EMB
participant "KnowledgeGraph\n(NetworkX)" as KG
participant "UserManager" as UM

-> RE: rank_search_results(results, processed_query, user_data)
activate RE

RE -> RE: Extract search parameters\nand user context

par Parallel Ranking Calculations
    RE -> RE: calculate_heuristic_scores()\n- Keyword matching in titles\n- Exact phrase bonuses\n- Field-specific scoring\n- Recency bonuses
    
    RE -> RE: calculate_tfidf_scores()\n- TF-IDF vectorization\n- Cosine similarity\n- N-gram analysis
    
    RE -> RE: calculate_intent_scores()\n- Resource type preferences\n- Academic field alignment\n- Intent confidence weighting
    
    RE -> EMB: calculate_embedding_similarity()
    activate EMB
    EMB -> EMB: Generate embeddings\nusing sentence transformers
    EMB -> EMB: Calculate cosine similarity
    EMB --> RE: embedding_scores[]
    deactivate EMB
    
    RE -> UM: get_personalization_data(user_id)
    activate UM
    UM --> RE: user_preferences,\ninteraction_history
    deactivate UM
    
    RE -> KG: get_authority_scores(results)
    activate KG
    KG -> KG: Build knowledge graph\nfrom results
    KG -> KG: Calculate PageRank\nauthority scores
    KG --> RE: graph_scores[]
    deactivate KG
end

alt LTR Model Available and Trained
    RE -> LTR: rank_results(query, results, features)
    activate LTR
    
    LTR -> LTR: extract_features()\n- 50+ engineered features\n- Text, metadata, user, graph features
    
    LTR -> LTR: XGBoost model prediction
    
    LTR --> RE: ltr_scores[]
    deactivate LTR
    
    RE -> RE: Hybrid Scoring:\n70% LTR + 30% Traditional\n= 0.7 * ltr_score + 0.3 * traditional_score
    
else LTR Not Available
    RE -> RE: Traditional Weighted Scoring:\n- 20% Heuristic\n- 20% TF-IDF\n- 20% Intent\n- 20% Embedding\n- 20% Personalization
end

RE -> RE: Add knowledge graph features\nto score breakdown

RE -> RE: categorize_by_relevance()\n- High: score > 0.7\n- Medium: 0.4 < score ≤ 0.7\n- Low: score ≤ 0.4

RE -> RE: Sort results by final ranking score

RE --> : Ranked Results with:\n- Final scores\n- Relevance categories\n- Score breakdown\n- Ranking metadata
deactivate RE

note over RE, KG
    Advanced Ranking Features:
    - Multi-algorithm fusion
    - Machine learning optimization
    - Knowledge graph authority
    - Real-time personalization
    - Semantic understanding
    - User behavior adaptation
end note

@enduml

/' ================================================================================================
   DIAGRAM 4: User Registration Flow - User Onboarding
   ================================================================================================ '/

@startuml UserRegistrationFlow
!theme plain
title 4. User Registration Flow - Complete User Onboarding

actor User as U
participant "Frontend\n(signup.html)" as FE
participant "Flask API" as API
participant "UserManager" as UM
participant "DatabaseManager" as DB
participant "MongoDB\n(APOSSS DB)" as MONGO
participant "EmailService\n(SMTP)" as EMAIL

U -> FE: Access signup page
activate FE

U -> FE: Fill registration form:\n- First/Last name\n- Username\n- Email\n- Password\n- Institution\n- Academic fields

FE -> API: POST /api/auth/check-username\n{username}
activate API
API -> UM: check_username_exists(username)
activate UM
UM -> DB: query users collection
activate DB
DB -> MONGO: find({username})
DB --> UM: exists/not_exists
deactivate DB
UM --> API: {exists: boolean}
deactivate UM
API --> FE: Username availability
deactivate API

FE -> API: POST /api/auth/check-email\n{email}
activate API
API -> UM: check_email_exists(email)
activate UM
UM -> DB: query users collection
activate DB
DB -> MONGO: find({email})
DB --> UM: exists/not_exists
deactivate DB
UM --> API: {exists: boolean}
deactivate UM
API --> FE: Email availability
deactivate API

FE -> FE: Client-side validation:\n- Password strength\n- Field completeness\n- Email format

U -> FE: Submit registration form

FE -> API: POST /api/auth/register\n{user_data}
activate API

API -> UM: register_user(user_data)
activate UM

UM -> UM: Validate registration data:\n- Check required fields\n- Validate email format\n- Check password strength

UM -> UM: Hash password using bcrypt

UM -> DB: Create user profile
activate DB

DB -> MONGO: Insert new user document:\n{\n  user_id, username, email,\n  hashed_password, profile_data,\n  created_at, email_verified: false\n}
activate MONGO
MONGO --> DB: user_created
deactivate MONGO

DB --> UM: User creation success
deactivate DB

UM -> UM: generate_verification_code()

UM -> DB: Store verification code
activate DB
DB -> MONGO: Insert verification_codes\n{user_id, code, expiry}
DB --> UM: Code stored
deactivate DB

UM -> EMAIL: send_verification_email(email, code)
activate EMAIL

EMAIL -> EMAIL: Render email template\nwith verification link

EMAIL -> EMAIL: SMTP connection\nand email sending

alt Email Sent Successfully
    EMAIL --> UM: Email delivery confirmed
    UM --> API: Registration successful\n{user_id, requires_verification}
else Email Failed
    EMAIL --> UM: Email delivery failed
    UM --> API: Registration successful\nbut email failed
end
deactivate EMAIL

UM -> UM: generate_jwt_token(user_id)

UM --> API: {success: true, user: {...}, token: "..."}
deactivate UM

API --> FE: Registration response
deactivate API

FE -> FE: Store JWT token\nin localStorage

FE --> U: Registration success\n+ verification required message
deactivate FE

note over U, MONGO
    Complete Registration Features:
    - Real-time field validation
    - Duplicate checking
    - Secure password hashing
    - Email verification system
    - JWT token generation
    - Academic profile setup
end note

@enduml

/' ================================================================================================
   DIAGRAM 5: User Login Flow - Authentication
   ================================================================================================ '/

@startuml UserLoginFlow
!theme plain
title 5. User Login Flow - Secure Authentication

actor User as U
participant "Frontend\n(login.html)" as FE
participant "Flask API" as API
participant "UserManager" as UM
participant "DatabaseManager" as DB
participant "MongoDB\n(APOSSS DB)" as MONGO
participant "JWT Service" as JWT

U -> FE: Access login page
activate FE

U -> FE: Enter credentials:\n- Email/Username\n- Password

FE -> FE: Client-side validation:\n- Required fields\n- Basic format check

U -> FE: Submit login form

FE -> API: POST /api/auth/login\n{identifier, password}
activate API

API -> UM: authenticate_user(identifier, password)
activate UM

UM -> DB: Find user by email or username
activate DB

DB -> MONGO: find({$or: [{email}, {username}]})
activate MONGO
MONGO --> DB: user_document or null
deactivate MONGO

alt User Found
    DB --> UM: user_data
    deactivate DB
    
    UM -> UM: verify_password(password, hashed_password)\nusing bcrypt
    
    alt Password Correct
        UM -> UM: check_email_verification_status()
        
        alt Email Verified
            UM -> JWT: generate_token(user_id)
            activate JWT
            JWT -> JWT: Create JWT with:\n- user_id\n- expiration (configurable)\n- secret key signing
            JWT --> UM: jwt_token
            deactivate JWT
            
            UM -> DB: Update last_login timestamp
            activate DB
            DB -> MONGO: update({user_id}, {last_login: now})
            DB --> UM: Updated
            deactivate DB
            
            UM -> UM: get_user_profile_data()
            
            UM --> API: {success: true,\nuser: {...},\ntoken: "...",\nmessage: "Login successful"}
            
        else Email Not Verified
            UM --> API: {success: false,\nerror: "email_not_verified",\nmessage: "Please verify your email"}
        end
        
    else Password Incorrect
        UM --> API: {success: false,\nerror: "invalid_credentials",\nmessage: "Invalid email/password"}
    end
    
else User Not Found
    DB --> UM: null
    deactivate DB
    UM --> API: {success: false,\nerror: "user_not_found",\nmessage: "Invalid email/password"}
end

deactivate UM

alt Login Successful
    API --> FE: {success: true, user: {...}, token: "..."}
    
    FE -> FE: Store JWT token in localStorage
    FE -> FE: Store user data in sessionStorage
    FE -> FE: Update UI state (logged in)
    FE --> U: Redirect to dashboard/search
    
else Login Failed
    API --> FE: {success: false, error: "...", message: "..."}
    FE -> FE: Display error message
    FE --> U: Show login error
end

deactivate API
deactivate FE

note over U, JWT
    Secure Authentication Features:
    - Email/Username flexible login
    - bcrypt password hashing
    - JWT token management
    - Email verification check
    - Session state management
    - Secure error handling
end note

@enduml

/' ================================================================================================
   DIAGRAM 6: Multi-Database Search Execution - Comprehensive Data Retrieval
   ================================================================================================ '/

@startuml MultiDatabaseSearch
!theme plain
title 6. Multi-Database Search Execution - Comprehensive Academic Data Retrieval

participant "SearchEngine" as SE
participant "DatabaseManager" as DM
database "Academic Library\n(books, journals, projects)" as AL
database "Experts System\n(experts, certificates)" as ES
database "Research Papers\n(articles, conferences, theses)" as RP
database "Laboratories\n(equipments, materials)" as LAB
database "Funding\n(projects, institutions)" as FUND
database "APOSSS\n(users, feedback)" as APOSSS

-> SE: search_all_databases(processed_query, filters)
activate SE

SE -> SE: extract_search_parameters():\n- Primary/secondary keywords\n- Entities (people, organizations)\n- Academic fields\n- Intent classification

SE -> DM: test_connections()
activate DM
DM --> SE: connection_status
deactivate DM

par Parallel Database Searches
    SE -> AL: search_academic_library(search_params)
    activate AL
    
    par Academic Library Collections
        AL -> AL: Search books collection:\n- title, author, description\n- keywords, category, abstract
        AL -> AL: Search journals collection:\n- title, editor, description\n- keywords, category, abstract  
        AL -> AL: Search projects collection:\n- title, student_name, supervisor\n- description, department, keywords
    end
    
    AL --> SE: academic_results[]
    deactivate AL
    
else
    SE -> ES: search_experts_system(search_params)
    activate ES
    
    par Experts System Collections
        ES -> ES: Search experts collection:\n- name, role, slogan\n- locations, specializations
        ES -> ES: Search certificates collection:\n- title, degree, institution\n- description, expert_id linking
    end
    
    ES --> SE: expert_results[]
    deactivate ES
    
else
    SE -> RP: search_research_papers(search_params)
    activate RP
    
    par Research Papers Collections
        RP -> RP: Search articles collection:\n- title, authors, abstract\n- keywords, categories
        RP -> RP: Search conferences collection:\n- title, authors, summary\n- primary_category
        RP -> RP: Search theses collection:\n- title, student_name, supervisor\n- abstract, defense_date
    end
    
    RP --> SE: research_results[]
    deactivate RP
    
else
    SE -> LAB: search_laboratories(search_params)
    activate LAB
    
    par Laboratory Collections
        LAB -> LAB: Search equipments collection:\n- equipment_name, description\n- model, specifications, status
        LAB -> LAB: Search materials collection:\n- material_name, description\n- properties, availability
    end
    
    LAB --> SE: lab_results[]
    deactivate LAB
    
else
    SE -> FUND: search_funding_system(search_params)
    activate FUND
    
    par Funding Collections
        FUND -> FUND: Search research_projects:\n- title, description, keywords\n- investigators, institutions
        FUND -> FUND: Search institutions:\n- name, description, type\n- location, specializations
        FUND -> FUND: Search funding_records:\n- title, amount, duration\n- funding_agency, status
    end
    
    FUND --> SE: funding_results[]
    deactivate FUND
    
else
    SE -> APOSSS: search_aposss_data(search_params)
    activate APOSSS
    
    APOSSS -> APOSSS: Search user interactions:\n- Successful queries\n- Popular resources\n- User preferences
    
    APOSSS --> SE: system_results[]
    deactivate APOSSS
end

SE -> SE: aggregate_results():\n- Merge all database results\n- Standardize document format\n- Remove duplicates\n- Add source metadata

SE -> SE: apply_database_filters()\nif specific databases requested

SE -> SE: result_standardization():\n- Unified result structure\n- Snippet generation\n- Metadata enrichment\n- Type classification

SE --> : Aggregated Search Results:\n{\n  "total_results": count,\n  "results": [...],\n  "database_coverage": {...},\n  "search_metadata": {...}\n}
deactivate SE

note over SE, APOSSS
    Comprehensive Search Features:
    - 6 specialized academic databases
    - Parallel query execution
    - Collection-specific search strategies
    - Result standardization
    - Error handling & fallbacks
    - Database filtering options
    - Metadata enrichment
end note

@enduml

/' ================================================================================================
   DIAGRAM 7: User Feedback Submission - Learning Data Collection
   ================================================================================================ '/

@startuml UserFeedbackSubmission
!theme plain
title 7. User Feedback Submission - Machine Learning Data Collection

actor User as U
participant "Frontend\n(results.html)" as FE
participant "Flask API" as API
participant "FeedbackSystem" as FS
participant "DatabaseManager" as DB
participant "MongoDB\n(APOSSS DB)" as MONGO
participant "JSON File\nStorage" as FILE

U -> FE: View search results
activate FE

U -> FE: Interact with result:\n- Rate result (1-5 stars)\n- Add comment\n- Mark as helpful/not helpful

FE -> FE: Validate feedback data:\n- Rating value (1-5)\n- Comment length limits\n- Required fields

U -> FE: Submit feedback

FE -> API: POST /api/feedback\n{\n  "query_id": "...",\n  "result_id": "...",\n  "rating": 5,\n  "feedback_type": "rating",\n  "comment": "Very helpful result",\n  "user_id": "..."\n}
activate API

API -> FS: submit_feedback(feedback_data)
activate FS

FS -> FS: validate_feedback():\n- Check required fields\n- Validate rating range (1-5)\n- Sanitize comment text\n- Verify query/result IDs

FS -> FS: enhance_feedback():\n- Add timestamp\n- Generate feedback_id\n- Add processing metadata\n- Calculate relevance score

par Dual Storage Strategy
    FS -> DB: Store in MongoDB (primary)
    activate DB
    
    DB -> MONGO: Insert feedback document:\n{\n  feedback_id, query_id, result_id,\n  user_id, rating, comment,\n  feedback_type, submitted_at,\n  processing_metadata\n}
    activate MONGO
    
    alt MongoDB Storage Successful
        MONGO --> DB: insertion_success
        DB --> FS: MongoDB storage confirmed
    else MongoDB Storage Failed
        MONGO --> DB: insertion_error
        DB --> FS: MongoDB storage failed
    end
    deactivate MONGO
    deactivate DB
    
else
    FS -> FILE: Store in JSON file (backup)
    activate FILE
    
    FILE -> FILE: Append to feedback.jsonl:\n{"feedback_id": "...", "rating": 5, ...}\n
    
    alt File Storage Successful
        FILE --> FS: File storage confirmed
    else File Storage Failed
        FILE --> FS: File storage failed
    end
    deactivate FILE
end

FS -> FS: update_statistics():\n- Update feedback counters\n- Calculate running averages\n- Update user statistics

alt Feedback Stored Successfully
    FS --> API: {success: true,\nmessage: "Feedback submitted",\nfeedback_id: "..."}
    
    API -> API: track_user_interaction():\n- Log feedback submission\n- Update user engagement metrics
    
    API --> FE: Success response
    
    FE -> FE: Update UI:\n- Show success message\n- Update rating display\n- Disable further rating for this result
    
    FE --> U: "Thank you for your feedback!"
    
else Feedback Storage Failed
    FS --> API: {success: false,\nerror: "storage_failed",\nmessage: "Failed to save feedback"}
    
    API --> FE: Error response
    
    FE -> FE: Show error message:\n"Failed to submit feedback. Please try again."
    
    FE --> U: Display error notification
end

deactivate FS
deactivate API
deactivate FE

note over U, FILE
    Robust Feedback Collection:
    - Dual storage (MongoDB + file backup)
    - Real-time validation
    - User interaction tracking
    - Statistical updates
    - Error handling & recovery
    - Data integrity assurance
end note

@enduml

/' ================================================================================================
   DIAGRAM 8: LTR Model Training Process - Machine Learning Pipeline
   ================================================================================================ '/

@startuml LTRModelTraining
!theme plain
title 8. LTR Model Training Process - Machine Learning Pipeline for Ranking Improvement

participant "Training\nScheduler" as SCHED
participant "LTRRanker" as LTR
participant "FeedbackSystem" as FS
participant "FeatureExtractor" as FE
participant "XGBoost\nModel" as XGB
participant "ModelStorage" as STORE
participant "ModelValidator" as VAL

-> SCHED: Scheduled training trigger\n(or manual via API)
activate SCHED

SCHED -> LTR: train_model(training_data)
activate LTR

LTR -> FS: get_training_data(min_feedback_count=50)
activate FS

FS -> FS: Query feedback database:\n- Collect user ratings\n- Filter by feedback quality\n- Minimum samples per query

FS -> FS: prepare_training_examples():\n- Create query-document pairs\n- Assign relevance labels (0-4)\n- Group by query for ranking

FS --> LTR: training_examples[]:\n[{query, document, features, relevance_label}]
deactivate FS

LTR -> FE: extract_features(training_examples)
activate FE

par Feature Extraction (50+ Features)
    FE -> FE: Textual Features:\n- BM25 scores (title, description)\n- N-gram matches\n- Term proximity\n- Exact phrase matches
    
    FE -> FE: Metadata Features:\n- Publication date recency\n- Authority metrics\n- Availability status\n- Document type preferences
    
    FE -> FE: User Behavior Features:\n- Click-through rates\n- Historical ratings\n- User preferences\n- Interaction patterns
    
    FE -> FE: Current Algorithm Features:\n- Heuristic scores\n- TF-IDF similarity\n- Intent alignment\n- Embedding similarity
    
    FE -> FE: Knowledge Graph Features:\n- PageRank authority\n- Connection strength\n- Network centrality\n- Citation counts
end

FE --> LTR: feature_matrix (DataFrame)\nwith 50+ engineered features
deactivate FE

LTR -> LTR: prepare_training_data():\n- Split into train/validation (80/20)\n- Create ranking groups\n- Normalize features\n- Handle missing values

LTR -> XGB: Initialize XGBoost Ranker\nwith pairwise ranking objective
activate XGB

XGB -> XGB: Set hyperparameters:\n- learning_rate: 0.1\n- max_depth: 6\n- n_estimators: 100\n- objective: 'rank:pairwise'

LTR -> XGB: train(features, labels, groups)

XGB -> XGB: Gradient boosting training:\n- Build decision trees\n- Optimize ranking loss\n- Feature importance calculation

XGB --> LTR: trained_model
deactivate XGB

LTR -> VAL: validate_model(model, validation_data)
activate VAL

VAL -> VAL: Calculate performance metrics:\n- NDCG@10 (primary metric)\n- Mean Average Precision\n- Ranking accuracy\n- Feature importance analysis

alt Model Performance Acceptable (NDCG > 0.7)
    VAL --> LTR: validation_passed:\n{ndcg: 0.85, map: 0.78, accuracy: 0.82}
    
    LTR -> STORE: save_model(model, metadata)
    activate STORE
    
    STORE -> STORE: Save XGBoost model:\n- Model file (.json)\n- Feature names\n- Training statistics\n- Performance metrics
    
    STORE --> LTR: model_saved_successfully
    deactivate STORE
    
    LTR -> LTR: update_model_status():\n- Mark as trained\n- Update feature names\n- Store training stats
    
    LTR --> SCHED: Training Success:\n{\n  "status": "success",\n  "metrics": {...},\n  "features_count": 52,\n  "training_samples": 1250\n}
    
else Model Performance Poor (NDCG < 0.7)
    VAL --> LTR: validation_failed:\n{ndcg: 0.45, issues: [...]}
    
    LTR -> LTR: analyze_failure():\n- Insufficient training data\n- Feature quality issues\n- Hyperparameter tuning needed
    
    LTR --> SCHED: Training Failed:\n{\n  "status": "failed",\n  "reason": "low_performance",\n  "ndcg": 0.45,\n  "recommendations": [...]\n}
end

deactivate VAL
deactivate LTR

SCHED -> SCHED: schedule_next_training():\nBased on feedback accumulation

SCHED --> : Training Complete\nModel ready for inference
deactivate SCHED

note over SCHED, STORE
    Advanced ML Training Pipeline:
    - Automated feature engineering (50+ features)
    - XGBoost pairwise ranking optimization
    - Comprehensive validation (NDCG, MAP)
    - Model versioning and storage
    - Performance monitoring
    - Continuous improvement cycle
end note

@enduml

/' ================================================================================================
   DIAGRAM 9: Google OAuth Authentication - Social Login
   ================================================================================================ '/

@startuml GoogleOAuthAuthentication
!theme plain
title 9. Google OAuth Authentication - Secure Social Login

actor User as U
participant "Frontend" as FE
participant "Flask API" as API
participant "OAuthManager" as OAUTH
participant "Google OAuth\nService" as GOOGLE
participant "UserManager" as UM
participant "MongoDB\n(APOSSS DB)" as MONGO

U -> FE: Click "Sign in with Google"
activate FE

FE -> API: GET /api/auth/google
activate API

API -> OAUTH: get_authorization_url('google')
activate OAUTH

OAUTH -> OAUTH: generate_state_token()\nfor CSRF protection

OAUTH -> OAUTH: build_authorization_url():\n- client_id\n- redirect_uri\n- scope (email, profile)\n- response_type=code\n- state token

OAUTH --> API: {\n  "success": true,\n  "authorization_url": "https://accounts.google.com/oauth/authorize?...",\n  "state": "secure_random_token"\n}
deactivate OAUTH

API --> FE: Authorization URL with state
deactivate API

FE -> FE: Store state token\nfor validation

FE --> U: Redirect to Google OAuth
deactivate FE

U -> GOOGLE: Complete Google authentication:\n- Login with Google credentials\n- Consent to app permissions
activate GOOGLE

GOOGLE -> GOOGLE: User authentication\nand consent processing

GOOGLE --> U: Redirect to callback URL:\n/api/auth/google/callback?code=...&state=...
deactivate GOOGLE

U -> API: GET /api/auth/google/callback\n?code=auth_code&state=token
activate API

API -> OAUTH: process_oauth_login('google', code, state)
activate OAUTH

OAUTH -> OAUTH: validate_state_token()\nfor security

OAUTH -> GOOGLE: Exchange authorization code for tokens:\nPOST /oauth2/v4/token\n{\n  "client_id": "...",\n  "client_secret": "...",\n  "code": "auth_code",\n  "grant_type": "authorization_code"\n}
activate GOOGLE

GOOGLE --> OAUTH: {\n  "access_token": "...",\n  "token_type": "Bearer",\n  "scope": "email profile"\n}
deactivate GOOGLE

OAUTH -> GOOGLE: Get user information:\nGET /oauth2/v2/userinfo\nAuthorization: Bearer access_token
activate GOOGLE

GOOGLE --> OAUTH: {\n  "id": "google_user_id",\n  "email": "user@gmail.com",\n  "verified_email": true,\n  "name": "John Doe",\n  "given_name": "John",\n  "family_name": "Doe",\n  "picture": "https://..."\n}
deactivate GOOGLE

OAUTH --> API: {\n  "success": true,\n  "user_info": {\n    "provider": "google",\n    "provider_id": "...",\n    "email": "...",\n    "name": "..."\n  }\n}
deactivate OAUTH

API -> UM: handle_oauth_user(user_info)
activate UM

UM -> MONGO: Check if user exists:\nfind({email: "user@gmail.com"})
activate MONGO

alt User Exists
    MONGO --> UM: existing_user_data
    
    UM -> UM: Link Google account\nif not already linked
    
    UM -> MONGO: Update user with Google provider info
    
else User Doesn't Exist
    MONGO --> UM: null
    
    UM -> UM: Create new user account:\n- Extract profile from Google data\n- Mark email as verified\n- Set default preferences
    
    UM -> MONGO: Insert new user:\n{\n  user_id, email, name,\n  google_id, email_verified: true,\n  created_at, provider: "google"\n}
end

deactivate MONGO

UM -> UM: generate_jwt_token(user_id)

UM --> API: {\n  "success": true,\n  "user": {...},\n  "token": "jwt_token",\n  "is_new_user": boolean\n}
deactivate UM

alt Authentication Successful
    API --> U: Redirect to frontend\nwith success params:\n/?token=...&user_id=...
    
    U -> FE: Frontend receives OAuth success
    activate FE
    
    FE -> FE: Extract token from URL\nand store in localStorage
    
    FE -> FE: Update authentication state
    
    FE --> U: Welcome message\nand redirect to dashboard
    deactivate FE
    
else Authentication Failed
    API --> U: Redirect to frontend\nwith error params:\n/?error=oauth_failed
    
    U -> FE: Frontend receives OAuth error
    activate FE
    
    FE --> U: Display error message:\n"Google authentication failed"
    deactivate FE
end

deactivate API

note over U, MONGO
    Secure OAuth Features:
    - CSRF protection with state tokens
    - Automatic account creation/linking
    - Email verification via Google
    - JWT token generation
    - Profile picture integration
    - Error handling and fallbacks
end note

@enduml

/' ================================================================================================
   DIAGRAM 10: System Health Monitoring - Operational Oversight
   ================================================================================================ '/

@startuml SystemHealthMonitoring
!theme plain
title 10. System Health Monitoring - Comprehensive System Oversight

participant "HealthMonitor\n(Scheduler)" as HM
participant "ComponentChecker" as CC
participant "DatabaseMonitor" as DM
participant "APIMonitor" as AM
participant "AlertSystem" as ALERT
participant "Dashboard\nUpdater" as DASH
database "MongoDB\nInstances" as MONGO
participant "External APIs\n(Gemini, OAuth)" as EXT_API

-> HM: Scheduled health check\n(every 30 seconds)
activate HM

HM -> HM: Initialize health check cycle

par Parallel Component Monitoring
    HM -> CC: check_core_components()
    activate CC
    
    par Core Component Checks
        CC -> CC: Check LLMProcessor:\n- Gemini API connectivity\n- Response time < 5s\n- Error rate < 5%
        
        CC -> CC: Check SearchEngine:\n- Database connections\n- FAISS index availability\n- Search response time
        
        CC -> CC: Check RankingEngine:\n- LTR model status\n- Embedding ranker health\n- Knowledge graph state
        
        CC -> CC: Check FeedbackSystem:\n- Storage accessibility\n- Write capabilities\n- Statistics calculation
        
        CC -> CC: Check UserManager:\n- Authentication services\n- JWT token validation\n- Profile operations
    end
    
    CC --> HM: component_status:\n{\n  "llm_processor": "healthy",\n  "search_engine": "healthy",\n  "ranking_engine": "degraded",\n  "feedback_system": "healthy",\n  "user_manager": "healthy"\n}
    deactivate CC
    
else
    HM -> DM: check_database_health()
    activate DM
    
    par Database Health Checks
        DM -> MONGO: Academic Library DB:\n- Connection test\n- Query response time\n- Collection availability
        
        DM -> MONGO: Experts System DB:\n- Connection test\n- Index performance\n- Document count validation
        
        DM -> MONGO: Research Papers DB:\n- Connection test\n- Search functionality\n- Storage capacity
        
        DM -> MONGO: Laboratories DB:\n- Connection test\n- Query optimization\n- Data integrity
        
        DM -> MONGO: Funding DB:\n- Connection test\n- Performance metrics\n- Availability status
        
        DM -> MONGO: APOSSS DB:\n- Connection test\n- User operations\n- Feedback storage
    end
    
    DM --> HM: database_status:\n{\n  "academic_library": {"status": "healthy", "response_time": "120ms"},\n  "experts_system": {"status": "healthy", "response_time": "95ms"},\n  "research_papers": {"status": "warning", "response_time": "340ms"},\n  ...\n}
    deactivate DM
    
else
    HM -> AM: check_api_endpoints()
    activate AM
    
    par API Endpoint Monitoring
        AM -> AM: Check /api/search:\n- Response time\n- Success rate\n- Error patterns
        
        AM -> AM: Check /api/auth/*:\n- Authentication flow\n- Token validation\n- OAuth providers
        
        AM -> AM: Check /api/feedback:\n- Submission rate\n- Storage success\n- Data validation
        
        AM -> EXT_API: Check external APIs:\n- Gemini API status\n- Google OAuth status\n- ORCID API status
    end
    
    AM --> HM: api_status:\n{\n  "search_endpoint": {"status": "healthy", "avg_response": "1.2s"},\n  "auth_endpoints": {"status": "healthy", "success_rate": "99.2%"},\n  "external_apis": {"gemini": "healthy", "google_oauth": "healthy"}\n}
    deactivate AM
end

HM -> HM: aggregate_health_data():\n- Calculate overall system health\n- Identify critical issues\n- Determine alert levels

HM -> HM: calculate_system_metrics():\n- Uptime percentage\n- Performance trends\n- Error rate analysis\n- Resource utilization

alt Critical Issues Detected
    HM -> ALERT: trigger_alerts(critical_issues)
    activate ALERT
    
    ALERT -> ALERT: Classify alert severity:\n- Critical: Service down\n- Warning: Performance degraded\n- Info: Minor issues
    
    par Alert Distribution
        ALERT -> ALERT: Send email notifications\nto administrators
        
        ALERT -> ALERT: Update monitoring dashboard\nwith alert status
        
        ALERT -> ALERT: Log alerts for\nhistorical analysis
    end
    
    ALERT --> HM: alerts_sent
    deactivate ALERT
    
else System Healthy
    HM -> HM: Log successful health check
end

HM -> DASH: update_dashboard(health_data)
activate DASH

DASH -> DASH: Update real-time metrics:\n- Component status indicators\n- Performance graphs\n- Alert summaries\n- Trend analysis

DASH -> DASH: Generate health report:\n- System overview\n- Performance metrics\n- Issue summaries\n- Recommendations

DASH --> HM: dashboard_updated
deactivate DASH

HM -> HM: schedule_next_check()\nBased on current system status

HM --> : Health Check Complete:\n{\n  "overall_status": "healthy",\n  "components_healthy": 5,\n  "components_degraded": 0,\n  "databases_healthy": 6,\n  "apis_healthy": 3,\n  "next_check": "2024-01-15T10:30:30Z"\n}
deactivate HM

note over HM, EXT_API
    Comprehensive Monitoring Features:
    - Real-time component health checks
    - Database performance monitoring
    - API endpoint status tracking
    - External service connectivity
    - Automated alert system
    - Performance trend analysis
    - Dashboard visualization
    - Historical data logging
end note

@enduml

@enduml 